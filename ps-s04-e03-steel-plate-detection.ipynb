{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":68699,"databundleVersionId":7659021,"sourceType":"competition"}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rubanzasilva/ps-s04-e03-fastai?scriptVersionId=169141486\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"### Imports\n\nIf you dont have the fastai library installed, uncomment the lines with pip install fastbook to install all the dependencies we shall need.","metadata":{}},{"cell_type":"code","source":"#hide\n#! [ -e /content ]\n\n#hide\n#This imports and sets up everything you will need for this notebook\n#\n!pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()\n\nfrom fastbook import *\nfrom fastai.tabular.all import *\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom numpy import random\n\nfrom fastai.imports import *\nnp.set_printoptions(linewidth=130)\n\n# for working with paths in Python, I recommend using `pathlib.Path`\nfrom pathlib import Path\nimport os\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom ipywidgets import interact\n\n\nmatplotlib.rc('image', cmap='Greys')","metadata":{"id":"RCMDyNwgY7G7","execution":{"iopub.status.busy":"2024-03-28T10:28:57.024047Z","iopub.execute_input":"2024-03-28T10:28:57.024711Z","iopub.status.idle":"2024-03-28T10:29:17.198965Z","shell.execute_reply.started":"2024-03-28T10:28:57.024656Z","shell.execute_reply":"2024-03-28T10:29:17.197925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Set random seed for reproducibility.","metadata":{"id":"Agl1BKpacH6v"}},{"cell_type":"code","source":"#random.seed(42)\nset_seed(42)","metadata":{"id":"jd7Hze9-cGtp","execution":{"iopub.status.busy":"2024-03-28T10:29:17.200803Z","iopub.execute_input":"2024-03-28T10:29:17.201269Z","iopub.status.idle":"2024-03-28T10:29:17.207044Z","shell.execute_reply.started":"2024-03-28T10:29:17.201242Z","shell.execute_reply":"2024-03-28T10:29:17.205935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-03-28T10:29:30.402154Z","iopub.execute_input":"2024-03-28T10:29:30.402997Z","iopub.status.idle":"2024-03-28T10:29:31.363206Z","shell.execute_reply.started":"2024-03-28T10:29:30.402957Z","shell.execute_reply":"2024-03-28T10:29:31.361996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Import Dataset","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"id":"ecCaoXLjbLdZ","outputId":"81e17a8a-b2d5-4dcf-f128-530ddeaf738a","execution":{"iopub.status.busy":"2024-03-28T10:29:41.271754Z","iopub.execute_input":"2024-03-28T10:29:41.272141Z","iopub.status.idle":"2024-03-28T10:29:41.281048Z","shell.execute_reply.started":"2024-03-28T10:29:41.272109Z","shell.execute_reply":"2024-03-28T10:29:41.280128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/input/playground-series-s4e3","metadata":{"execution":{"iopub.status.busy":"2024-03-28T10:01:37.636036Z","iopub.execute_input":"2024-03-28T10:01:37.636422Z","iopub.status.idle":"2024-03-28T10:01:38.659731Z","shell.execute_reply.started":"2024-03-28T10:01:37.636392Z","shell.execute_reply":"2024-03-28T10:01:38.65875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = Path('/kaggle/input/playground-series-s4e3')\npath","metadata":{"id":"i4VhYuv3cztD","outputId":"aec8185a-163e-434a-9705-dad68e45215a","execution":{"iopub.status.busy":"2024-03-28T10:29:46.082255Z","iopub.execute_input":"2024-03-28T10:29:46.082952Z","iopub.status.idle":"2024-03-28T10:29:46.090702Z","shell.execute_reply.started":"2024-03-28T10:29:46.082922Z","shell.execute_reply":"2024-03-28T10:29:46.089762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Read in Datasets","metadata":{"id":"K1hn53PnA3h4"}},{"cell_type":"code","source":"train_df = pd.read_csv(path/'train.csv')\ntest_df = pd.read_csv(path/'test.csv')\nsub_df = pd.read_csv(path/'sample_submission.csv')","metadata":{"id":"vsMF74KpczqS","execution":{"iopub.status.busy":"2024-03-28T10:29:53.747016Z","iopub.execute_input":"2024-03-28T10:29:53.747365Z","iopub.status.idle":"2024-03-28T10:29:54.115738Z","shell.execute_reply.started":"2024-03-28T10:29:53.747338Z","shell.execute_reply":"2024-03-28T10:29:54.114574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-28T10:01:39.796905Z","iopub.execute_input":"2024-03-28T10:01:39.798252Z","iopub.status.idle":"2024-03-28T10:01:39.84467Z","shell.execute_reply.started":"2024-03-28T10:01:39.798219Z","shell.execute_reply":"2024-03-28T10:01:39.843675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-28T10:01:40.151526Z","iopub.execute_input":"2024-03-28T10:01:40.152446Z","iopub.status.idle":"2024-03-28T10:01:40.174734Z","shell.execute_reply.started":"2024-03-28T10:01:40.152398Z","shell.execute_reply":"2024-03-28T10:01:40.173525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.shape,train_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-28T10:01:41.484212Z","iopub.execute_input":"2024-03-28T10:01:41.48505Z","iopub.status.idle":"2024-03-28T10:01:41.491382Z","shell.execute_reply.started":"2024-03-28T10:01:41.485016Z","shell.execute_reply":"2024-03-28T10:01:41.490277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets create a list called y_names of our dependent variables / targets","metadata":{}},{"cell_type":"code","source":"y_names = ['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']","metadata":{"id":"gmHUkX9ddGUJ","execution":{"iopub.status.busy":"2024-03-28T10:30:04.298278Z","iopub.execute_input":"2024-03-28T10:30:04.298892Z","iopub.status.idle":"2024-03-28T10:30:04.303498Z","shell.execute_reply.started":"2024-03-28T10:30:04.298859Z","shell.execute_reply":"2024-03-28T10:30:04.302341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cont_names, cat_names = cont_cat_split(train_df,dep_var=['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults'])","metadata":{"id":"pPvV47yfeoqL","execution":{"iopub.status.busy":"2024-03-28T10:30:04.764686Z","iopub.execute_input":"2024-03-28T10:30:04.765035Z","iopub.status.idle":"2024-03-28T10:30:04.780828Z","shell.execute_reply.started":"2024-03-28T10:30:04.765007Z","shell.execute_reply":"2024-03-28T10:30:04.780003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"splits = RandomSplitter(valid_pct=0.2)(range_of(train_df))","metadata":{"id":"h8YwkIl9gJu_","execution":{"iopub.status.busy":"2024-03-28T10:30:06.123627Z","iopub.execute_input":"2024-03-28T10:30:06.123999Z","iopub.status.idle":"2024-03-28T10:30:06.155996Z","shell.execute_reply.started":"2024-03-28T10:30:06.123972Z","shell.execute_reply":"2024-03-28T10:30:06.155213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### TabularPandas Object\n\nWe create an instance of a TabularPandas Object,to which is a fastai dataframe wrapper that stores all the information about our dataset such as which columns are continous, categorical, and our dependent variables. \n\nThis instance also stores and applies the set transformations to our data.","metadata":{}},{"cell_type":"code","source":"to = TabularPandas(train_df, procs=[Categorify, FillMissing,Normalize],\n                   cat_names = cat_names,\n                   cont_names = cont_names,\n                   y_names= y_names,\n                  # y_block = CategoryBlock,\n                   splits=splits)","metadata":{"id":"UgDbuCuBdGRM","execution":{"iopub.status.busy":"2024-03-28T10:30:12.404331Z","iopub.execute_input":"2024-03-28T10:30:12.404696Z","iopub.status.idle":"2024-03-28T10:30:12.485776Z","shell.execute_reply.started":"2024-03-28T10:30:12.404656Z","shell.execute_reply":"2024-03-28T10:30:12.48485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to.xs.iloc[:2]","metadata":{"id":"ZiCcYfSydGOy","outputId":"6ad4e817-8c09-4340-dd3f-d8cd5e6b88de","execution":{"iopub.status.busy":"2024-03-28T10:30:14.246464Z","iopub.execute_input":"2024-03-28T10:30:14.247397Z","iopub.status.idle":"2024-03-28T10:30:14.28542Z","shell.execute_reply.started":"2024-03-28T10:30:14.247355Z","shell.execute_reply":"2024-03-28T10:30:14.284218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now go ahead and create a dataloaders object which loads the data in a given batch size. Before loading the data the transforms are applied.","metadata":{}},{"cell_type":"code","source":"dls = to.dataloaders(bs=64)","metadata":{"id":"URgqOShbdGL6","execution":{"iopub.status.busy":"2024-03-28T09:48:42.044391Z","iopub.execute_input":"2024-03-28T09:48:42.045001Z","iopub.status.idle":"2024-03-28T09:48:42.130184Z","shell.execute_reply.started":"2024-03-28T09:48:42.044972Z","shell.execute_reply":"2024-03-28T09:48:42.129196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dls.show_batch()","metadata":{"id":"qKSy2-hMdGJM","outputId":"c41dba85-216d-437c-de8e-8afbd927348c","execution":{"iopub.status.busy":"2024-03-28T09:48:42.619694Z","iopub.execute_input":"2024-03-28T09:48:42.620068Z","iopub.status.idle":"2024-03-28T09:48:42.683443Z","shell.execute_reply.started":"2024-03-28T09:48:42.62004Z","shell.execute_reply":"2024-03-28T09:48:42.68257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tabular Model\n\nWe can define our model by using the tabular_learner method which returns a learner that includes a tabularModel which creates a basic model for our tabular data while infering the right loss function.","metadata":{}},{"cell_type":"code","source":"learn = tabular_learner(dls, metrics=RocAucMulti())","metadata":{"id":"zgoR-q0fdGGk","execution":{"iopub.status.busy":"2024-03-28T09:48:43.972298Z","iopub.execute_input":"2024-03-28T09:48:43.973028Z","iopub.status.idle":"2024-03-28T09:48:44.010539Z","shell.execute_reply.started":"2024-03-28T09:48:43.972996Z","shell.execute_reply":"2024-03-28T09:48:44.008981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.lr_find(suggest_funcs=(slide,valley))","metadata":{"id":"IPyazzCaPcNi","outputId":"26eac142-bc36-4b6f-8f55-a7390ede093e","execution":{"iopub.status.busy":"2024-03-28T09:48:44.658016Z","iopub.execute_input":"2024-03-28T09:48:44.65838Z","iopub.status.idle":"2024-03-28T09:48:47.09614Z","shell.execute_reply.started":"2024-03-28T09:48:44.658349Z","shell.execute_reply":"2024-03-28T09:48:47.095207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#learn.fit_one_cycle(15, slice(0.0005, 0.019))\nlearn.fit_one_cycle(12, 0.014)","metadata":{"id":"BJV69bfWTGFR","execution":{"iopub.status.busy":"2024-03-28T09:48:47.097862Z","iopub.execute_input":"2024-03-28T09:48:47.098625Z","iopub.status.idle":"2024-03-28T09:49:15.487566Z","shell.execute_reply.started":"2024-03-28T09:48:47.098589Z","shell.execute_reply":"2024-03-28T09:49:15.486691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.show_results()","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:50:04.846758Z","iopub.execute_input":"2024-03-28T09:50:04.847166Z","iopub.status.idle":"2024-03-28T09:50:04.909219Z","shell.execute_reply.started":"2024-03-28T09:50:04.847122Z","shell.execute_reply":"2024-03-28T09:50:04.908309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dl = learn.dls.test_dl(test_df)\n\nnn_preds = learn.get_preds(dl=dl)\nnn_preds","metadata":{"id":"0Rk3-KECy9a4","outputId":"5b71dbe3-4e63-411e-c497-ce614a2edb1d","execution":{"iopub.status.busy":"2024-03-28T09:50:11.556553Z","iopub.execute_input":"2024-03-28T09:50:11.55691Z","iopub.status.idle":"2024-03-28T09:50:12.519491Z","shell.execute_reply.started":"2024-03-28T09:50:11.556884Z","shell.execute_reply":"2024-03-28T09:50:12.518128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"nn_preds returns the predictions from the model","metadata":{}},{"cell_type":"code","source":"nn_preds_x = learn.get_preds()[0]\nnn_preds_x","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:49:16.532219Z","iopub.status.idle":"2024-03-28T09:49:16.53257Z","shell.execute_reply.started":"2024-03-28T09:49:16.532379Z","shell.execute_reply":"2024-03-28T09:49:16.532393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can create a submission file for our tabular_learner model by uncommenting and running the cell below.","metadata":{}},{"cell_type":"code","source":"#target_preds = preds[0]\n#targets =['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']\n#test_df[targets] = target_preds\n\n#test_df.to_csv('submission.csv', columns=['id','Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults'], index=False)\n\n#sub = pd.read_csv('submission.csv')\n#sub.head()","metadata":{"id":"xc3wGzi_2XVD","execution":{"iopub.status.busy":"2024-03-28T09:49:16.533756Z","iopub.status.idle":"2024-03-28T09:49:16.534055Z","shell.execute_reply.started":"2024-03-28T09:49:16.533905Z","shell.execute_reply":"2024-03-28T09:49:16.533918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Neural Network Ensemble","metadata":{"id":"nsQFB_tsRJkG"}},{"cell_type":"code","source":"learn.lr_find(suggest_funcs=(slide,valley))","metadata":{"id":"il-F9qwWJ1ob","outputId":"bce5b377-31a4-4b99-e051-bcd5b84005c0","execution":{"iopub.status.busy":"2024-03-28T09:49:16.535023Z","iopub.status.idle":"2024-03-28T09:49:16.535371Z","shell.execute_reply.started":"2024-03-28T09:49:16.535206Z","shell.execute_reply":"2024-03-28T09:49:16.53522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dl = learn.dls.test_dl(test_df)","metadata":{"id":"mSBeoFkWKRc2","execution":{"iopub.status.busy":"2024-03-28T09:49:16.536348Z","iopub.status.idle":"2024-03-28T09:49:16.536677Z","shell.execute_reply.started":"2024-03-28T09:49:16.536522Z","shell.execute_reply":"2024-03-28T09:49:16.536536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ensemble():\n    learn = tabular_learner(dls, metrics=RocAucMulti())\n    with learn.no_bar(),learn.no_logging(): learn.fit(12, 0.014)\n    return learn.get_preds(dl=dl)[0]","metadata":{"id":"q0yVYx1j9dNC","execution":{"iopub.status.busy":"2024-03-28T09:49:16.538405Z","iopub.status.idle":"2024-03-28T09:49:16.538739Z","shell.execute_reply.started":"2024-03-28T09:49:16.538588Z","shell.execute_reply":"2024-03-28T09:49:16.538601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learns = [ensemble() for _ in range(5)]","metadata":{"id":"nNuFSIBj9dKN","outputId":"4b9e0da7-9400-4080-d849-facee1be7b0f","execution":{"iopub.status.busy":"2024-03-28T09:49:16.539883Z","iopub.status.idle":"2024-03-28T09:49:16.540181Z","shell.execute_reply.started":"2024-03-28T09:49:16.540033Z","shell.execute_reply":"2024-03-28T09:49:16.540046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ens_preds = torch.stack(learns).mean(0)","metadata":{"id":"PRnGbn9lRUo3","execution":{"iopub.status.busy":"2024-03-28T09:50:20.993972Z","iopub.execute_input":"2024-03-28T09:50:20.99433Z","iopub.status.idle":"2024-03-28T09:50:20.998797Z","shell.execute_reply.started":"2024-03-28T09:50:20.994301Z","shell.execute_reply":"2024-03-28T09:50:20.997802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#targets =['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']\n#test_df[targets] = ens_preds\n\n#test_df.to_csv('submission.csv', columns=['id','Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults'], index=False)\n\n#ens_sub = pd.read_csv('submission.csv')\n#ens_sub.head()","metadata":{"id":"38PaodywTPL-","outputId":"bdcecad9-b7f3-46a5-c0c1-511b2207434c","execution":{"iopub.status.busy":"2024-03-15T10:15:25.523333Z","iopub.execute_input":"2024-03-15T10:15:25.523685Z","iopub.status.idle":"2024-03-15T10:15:25.705335Z","shell.execute_reply.started":"2024-03-15T10:15:25.523654Z","shell.execute_reply":"2024-03-15T10:15:25.704158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forests","metadata":{}},{"cell_type":"code","source":"X_train, y_train = to.train.xs, to.train.ys.values\nX_test, y_test = to.valid.xs, to.valid.ys.values\n\nrf = RandomForestClassifier(100, min_samples_leaf=5)\nrf.fit(X_train, y_train);\n#mean_absolute_error(y_test, rf.predict(X_test))\n\nroc_auc_score(y_test, rf.predict(X_test))","metadata":{"execution":{"iopub.status.busy":"2024-03-28T10:31:23.855933Z","iopub.execute_input":"2024-03-28T10:31:23.856821Z","iopub.status.idle":"2024-03-28T10:31:34.468236Z","shell.execute_reply.started":"2024-03-28T10:31:23.856776Z","shell.execute_reply":"2024-03-28T10:31:34.467164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Kaggle Submission","metadata":{}},{"cell_type":"code","source":"preds = rf.predict(X_test)\n\n# Assuming `test_df` is your test DataFrame and it has an 'id' column\n# Create a DataFrame for the submission\nsub_df = pd.DataFrame(preds, columns=['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults'])\nsub_df['id'] = test_df['id'] # Add the 'id' column from the test data\n\n# Reorder the columns to match the submission format\nsub_df = sub_df[['id', 'Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']]\n\n# Save the submission DataFrame as a CSV file\nsub_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T10:32:12.512428Z","iopub.execute_input":"2024-03-28T10:32:12.513351Z","iopub.status.idle":"2024-03-28T10:32:12.798738Z","shell.execute_reply.started":"2024-03-28T10:32:12.513304Z","shell.execute_reply":"2024-03-28T10:32:12.797725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming `rf` is your trained model and `X_test` is your test data\n# Make predictions\npreds = rf.predict(X_test)\n\n# Assuming `test_df` is your test DataFrame and it has an 'id' column\n# Create a DataFrame for the submission\nsub_df = pd.DataFrame(preds, columns=['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults'])\nsub_df['id'] = test_df['id'] # Add the 'id' column from the test data\n\n# Reorder the columns to match the submission format\nsub_df = sub_df[['id', 'Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']]\n\n# Save the submission DataFrame as a CSV file\nsub_df.to_csv('submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-28T10:02:07.862977Z","iopub.execute_input":"2024-03-28T10:02:07.863695Z","iopub.status.idle":"2024-03-28T10:02:08.16244Z","shell.execute_reply.started":"2024-03-28T10:02:07.863663Z","shell.execute_reply":"2024-03-28T10:02:08.161368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-03-28T10:32:16.947575Z","iopub.execute_input":"2024-03-28T10:32:16.948562Z","iopub.status.idle":"2024-03-28T10:32:17.927841Z","shell.execute_reply.started":"2024-03-28T10:32:16.948518Z","shell.execute_reply":"2024-03-28T10:32:17.926688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming `sub_df` is your DataFrame that needs the 'id' column converted\n# Convert 'id' column to Int32 by rounding the floating-point numbers\n#submission_df['id'] = submission_df['id'].round().astype('Int32')\n\n# Now, 'id' column is of type Int32\n#print(submission_df['id'].dtype)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T08:44:42.626711Z","iopub.execute_input":"2024-03-27T08:44:42.627198Z","iopub.status.idle":"2024-03-27T08:44:42.635315Z","shell.execute_reply.started":"2024-03-27T08:44:42.627165Z","shell.execute_reply":"2024-03-27T08:44:42.633913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the submission DataFrame to a CSV file\nsubmission_df.to_csv('submission1.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T08:45:13.399454Z","iopub.execute_input":"2024-03-27T08:45:13.400825Z","iopub.status.idle":"2024-03-27T08:45:13.423519Z","shell.execute_reply.started":"2024-03-27T08:45:13.400772Z","shell.execute_reply":"2024-03-27T08:45:13.421972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-03-27T08:45:15.611904Z","iopub.execute_input":"2024-03-27T08:45:15.613185Z","iopub.status.idle":"2024-03-27T08:45:16.717825Z","shell.execute_reply.started":"2024-03-27T08:45:15.613131Z","shell.execute_reply":"2024-03-27T08:45:16.716353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sub_df = pd.read_csv(path/'sample_submission.csv')\nsub_tree = pd.read_csv('submission2.csv')","metadata":{"execution":{"iopub.status.busy":"2024-03-27T08:47:02.484305Z","iopub.execute_input":"2024-03-27T08:47:02.484928Z","iopub.status.idle":"2024-03-27T08:47:02.50193Z","shell.execute_reply.started":"2024-03-27T08:47:02.484872Z","shell.execute_reply":"2024-03-27T08:47:02.500568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_tree.info()","metadata":{"execution":{"iopub.status.busy":"2024-03-27T08:47:39.797112Z","iopub.execute_input":"2024-03-27T08:47:39.797519Z","iopub.status.idle":"2024-03-27T08:47:39.813868Z","shell.execute_reply.started":"2024-03-27T08:47:39.797489Z","shell.execute_reply":"2024-03-27T08:47:39.812603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T08:48:21.776168Z","iopub.execute_input":"2024-03-27T08:48:21.776761Z","iopub.status.idle":"2024-03-27T08:48:21.807128Z","shell.execute_reply.started":"2024-03-27T08:48:21.776717Z","shell.execute_reply":"2024-03-27T08:48:21.805923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sub_df['id'].dtype)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T08:45:38.750891Z","iopub.execute_input":"2024-03-27T08:45:38.75129Z","iopub.status.idle":"2024-03-27T08:45:38.757759Z","shell.execute_reply.started":"2024-03-27T08:45:38.75126Z","shell.execute_reply":"2024-03-27T08:45:38.756382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#target_preds = preds[0]\n#target_preds","metadata":{"execution":{"iopub.status.busy":"2024-03-27T06:40:05.79589Z","iopub.execute_input":"2024-03-27T06:40:05.79635Z","iopub.status.idle":"2024-03-27T06:40:05.802196Z","shell.execute_reply.started":"2024-03-27T06:40:05.796317Z","shell.execute_reply":"2024-03-27T06:40:05.800749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Submit Outside Kaggle.","metadata":{}},{"cell_type":"code","source":"#!kaggle competitions submit -c playground-series-s4e3 -f submission.csv -m \"fastai baseline, adding lr fron lr finder\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Full Notebook","metadata":{}},{"cell_type":"code","source":"from fastai.tabular.all import *\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n#hide\n#! [ -e /content ]\n\n#hide\n#This imports and sets up everything you will need for this notebook\n#\n#!pip install -Uqq fastbook\n#import fastbook\n#fastbook.setup_book()\n\n#from fastbook import *\nfrom fastai.tabular.all import *\n\nfrom fastai.imports import *\nnp.set_printoptions(linewidth=130)\n\n# for working with paths in Python, I recommend using `pathlib.Path`\nfrom pathlib import Path\nimport os\nimport seaborn as sns\nimport numpy as np\nfrom numpy import random\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\n\nfrom ipywidgets import interact\n\n\n\nmatplotlib.rc('image', cmap='Greys')\n\nrandom.seed(42)\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\npath = Path('/kaggle/input/playground-series-s4e3')\npath\n\ntrain_df = pd.read_csv(path/'train.csv')\ntest_df = pd.read_csv(path/'test.csv')\nsub_df = pd.read_csv(path/'sample_submission.csv')\n\ny_names = ['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']\n\ncont_names, cat_names = cont_cat_split(train_df,dep_var=['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults'])\n\nsplits = RandomSplitter(valid_pct=0.2)(range_of(train_df))\n\nto = TabularPandas(train_df, procs=[Categorify, FillMissing,Normalize],\n                   cat_names = cat_names,\n                   cont_names = cont_names,\n                   y_names= y_names,\n                  # y_block = CategoryBlock,\n                   splits=splits)\n\n#X_train, y_train = to.train.xs, to.train.ys.values.ravel()\n#X_test, y_test = to.valid.xs, to.valid.ys.values.ravel()\n\nX_train, y_train = to.train.xs, to.train.ys.values\nX_test, y_test = to.valid.xs, to.valid.ys.values\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score\n\nrf = RandomForestClassifier(100, min_samples_leaf=5)\nrf.fit(X_train, y_train);\n#mean_absolute_error(y_test, rf.predict(X_test))\n\nroc_auc_score(y_test, rf.predict(X_test))","metadata":{"execution":{"iopub.status.busy":"2024-03-27T06:38:42.213875Z","iopub.execute_input":"2024-03-27T06:38:42.214344Z","iopub.status.idle":"2024-03-27T06:38:43.330295Z","shell.execute_reply.started":"2024-03-27T06:38:42.214309Z","shell.execute_reply":"2024-03-27T06:38:43.32869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\npath = Path('/kaggle/input/playground-series-s4e3')\npath\n\ntrain_df = pd.read_csv(path/'train.csv')\ntest_df = pd.read_csv(path/'test.csv')\nsub_df = pd.read_csv(path/'sample_submission.csv')\n\ny_names = ['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']\n\ncont_names, cat_names = cont_cat_split(train_df,dep_var=['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults'])\n\nsplits = RandomSplitter(valid_pct=0.2)(range_of(train_df))\n\nto = TabularPandas(train_df, procs=[Categorify, FillMissing,Normalize],\n                   cat_names = cat_names,\n                   cont_names = cont_names,\n                   y_names= y_names,\n                  # y_block = CategoryBlock,\n                   splits=splits)\n\ndls = to.dataloaders(bs=64)\n\ndl = learn.dls.test_dl(test_df)\n\nlearn = tabular_learner(dls, metrics=RocAucMulti())\n\n#learn.fit_one_cycle(15, slice(0.0005, 0.019))\nlearn.fit_one_cycle(12, 0.014)\n\n\npreds = learn.get_preds(dl=dl)\n\n\ntarget_preds = preds[0]\ntargets =['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']\ntest_df[targets] = target_preds\n\ntest_df.to_csv('submission.csv', columns=['id','Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults'], index=False)\n\n#sub = pd.read_csv('submission.csv')\n#sub.head()","metadata":{},"execution_count":null,"outputs":[]}]}